# Todo

## 2020-01-07
- [x] Vul todo in.

## 2020-01-10
- [ ] Send information to Nicolaas Heyning.
    - [ ] Ellis
    - [x] Stefan
    - [ ] Thomas
- [ ] Read about neural networks: https://www.3blue1brown.com/neural-networks
    - [X] Ellis
    - [x] Stefan
    - [ ] Thomas
- [ ] Understand Pytorch example: https://colab.research.google.com/drive/1arq7ZpWoO4Xw1od_RbMTHCl5IwIoYXOZ
    - [X] Ellis
    - [X] Stefan
    - [ ] Thomas
- [ ] Papers en blogs over pruning lezen.
    - [X] Ellis
    - [X] Stefan
    - [ ] Thomas
- [ ] Pytorch pipeline hebben voor MNIST.
- [ ] Notebook om dit te demonstreren.
- [ ] Optioneel: pipeline voor CIFAR-10 hebben.
- [ ] Optioneel: notebook om dit te demonstreren.

# Week 2

## 2020-01-14
- [ ] Step 1 & 2 from the project proposal:
    - [ ] 1: Implement a feedforward neural network and train it on the MNIST dataset.
    - [ ] 2: Implement a convolutional neural network and train it on the CIFAR10/MNIST dataset.
    - (when done, send Andrei mail for pruning code)

## 2020-01-16
- [ ] Step 3 from the project proposal:
    - [ ] Implement pruning mechanism.
    - [ ] Implement resetting function.
    
# Week 3

## 2020-01-21
- [ ] Step 4 from the project proposal:
    - [ ] Experimenting with different initialisation schemas.
          - [ ] Multiple runs with different seeds
          - [ ]  Answer: Does the initialization schema of a network affect its robustness to pruning.

## 2020-01-23
- [ ] Step 5 from the project proposal:
    - [ ] Determine for both of the above networks, and at varying degrees of sparsity levels, which schema works best and why.

# Week 4

## 2020-01-28
- [ ] Step 6 & 7 from the project proposal:
    - [ ] Based on the above results, is it possible, then, to construct a custom initialization schema that improves the robustness further?
    - [ ] Check whether the schema built on (6) generalizes to other pruning methods.

## 2020-01-28
- [ ] Presentations
    - [ ] Powerpoint (?)
    - [ ] Text

## 2020-01-31
- [ ] Final Report
