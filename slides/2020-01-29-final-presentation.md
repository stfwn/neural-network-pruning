---
title: One Initialization to Rule Them All
author: Stefan Wijnja, Ellis Wierstra, Thomas Hamburger
date: \today{}
---

# Neural networks are very cool

* Images of cool applications.

# But they can be very demanding

* Numbers for huge networks and how long it takes to train them.

# One possible solution: pruning

* Explain pruning, iterative pruning, discuss known results so far.

# Pruning can lead to Winning Tickets

* Explain what winning tickets are.

# Question

## Does weight initialization matter looking for Winning Tickets?

# Method

## Model

* Fully Connected.
* Two hidden layers: 300 & 100 neurons $\rightarrow$ 266k weights.

## Training


## Pruning

* Used LeNet on MNIST and tried a bunch of different inits. Nice summary on
  framework(s) used, how many lines of code written, how many epochs trained,
  etc.>

# Results

* Nice graphs of pruning rate vs. test_acc.

# Further Research

* What does this research lead to?

# Questions?
